{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "# Let's define a new Model that will take an image as input, and will output\n",
    "# intermediate representations for all layers in the previous model after\n",
    "# the first.\n",
    "successive_outputs = [layer.output for layer in model.layers[1:]]\n",
    "\n",
    "# visualization_model = Model(img_input, successive_outputs)\n",
    "visualization_model = tf.keras.models.Model(inputs=model.input, outputs=successive_outputs)\n",
    "\n",
    "# Let's prepare a random input image of a cat or dog from the training set.\n",
    "cat_img_files = [os.path.join(train_cats_dir, f) for f in train_cat_fnames]\n",
    "dog_img_files = [os.path.join(train_dogs_dir, f) for f in train_dog_fnames]\n",
    "\n",
    "img_path = random.choice(cat_img_files + dog_img_files)\n",
    "img = load_img(img_path, target_size=(150, 150))  # this is a PIL image\n",
    "\n",
    "x = img_to_array(img)  # Numpy array with shape (150, 150, 3)\n",
    "x = x.reshape((1,) + x.shape)  # Numpy array with shape (1, 150, 150, 3)\n",
    "\n",
    "# Rescale by 1/255\n",
    "x /= 255.0\n",
    "\n",
    "# Let's run our image through our network, thus obtaining all\n",
    "# intermediate representations for this image.\n",
    "successive_feature_maps = visualization_model.predict(x)\n",
    "\n",
    "# These are the names of the layers, so can have them as part of our plot\n",
    "layer_names = [layer.name for layer in model.layers]\n",
    "\n",
    "# -----------------------------------------------------------------------\n",
    "# Now let's display our representations\n",
    "# -----------------------------------------------------------------------\n",
    "for layer_name, feature_map in zip(layer_names, successive_feature_maps):\n",
    "\n",
    "    if len(feature_map.shape) == 4:\n",
    "\n",
    "        # -------------------------------------------\n",
    "        # Just do this for the conv / maxpool layers, not the fully-connected layers\n",
    "        # -------------------------------------------\n",
    "        n_features = feature_map.shape[-1]  # number of features in the feature map\n",
    "        size = feature_map.shape[1]  # feature map shape (1, size, size, n_features)\n",
    "\n",
    "        # We will tile our images in this matrix\n",
    "        display_grid = np.zeros((size, size * n_features))\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # Postprocess the feature to be visually palatable\n",
    "        # -------------------------------------------------\n",
    "        for i in range(n_features):\n",
    "            x = feature_map[0, :, :, i]\n",
    "            x -= x.mean()\n",
    "            x /= x.std()\n",
    "            x *= 64\n",
    "            x += 128\n",
    "            x = np.clip(x, 0, 255).astype('uint8')\n",
    "            display_grid[:, i * size: (i + 1) * size] = x  # Tile each filter into a horizontal grid\n",
    "\n",
    "        # -----------------\n",
    "        # Display the grid\n",
    "        # -----------------\n",
    "\n",
    "        scale = 20. / n_features\n",
    "        plt.figure(figsize=(scale * n_features, scale))\n",
    "        plt.title(layer_name)\n",
    "        plt.grid(False)\n",
    "        plt.imshow(display_grid, aspect='auto', cmap='viridis') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
